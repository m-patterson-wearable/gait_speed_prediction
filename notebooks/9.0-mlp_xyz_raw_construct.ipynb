{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref='nb92-' #Note to matt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "matplotlib.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'axes.titlesize':16,\n",
    "    'axes.labelsize':16,\n",
    "    'axes.xmargin':0.1,\n",
    "    'axes.ymargin':0.1,\n",
    "    'legend.fontsize':16,\n",
    "    'xtick.labelsize' : 16,\n",
    "    'ytick.labelsize' : 16,\n",
    "    'lines.markersize': 10,\n",
    "    'lines.linewidth' : 3,\n",
    "    'font.size': 16\n",
    "})\n",
    "\n",
    "\n",
    "import pickle \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "import mlflow.tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-426.0</td>\n",
       "      <td>-413.0</td>\n",
       "      <td>-394.0</td>\n",
       "      <td>-367.0</td>\n",
       "      <td>-340.0</td>\n",
       "      <td>-313.0</td>\n",
       "      <td>-286.0</td>\n",
       "      <td>-261.0</td>\n",
       "      <td>-235.0</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.133031</td>\n",
       "      <td>1.527700e+09</td>\n",
       "      <td>52-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-362.0</td>\n",
       "      <td>-362.0</td>\n",
       "      <td>-362.0</td>\n",
       "      <td>-352.0</td>\n",
       "      <td>-343.0</td>\n",
       "      <td>-326.0</td>\n",
       "      <td>-324.0</td>\n",
       "      <td>-310.0</td>\n",
       "      <td>-299.0</td>\n",
       "      <td>-292.0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.328511</td>\n",
       "      <td>1.527700e+09</td>\n",
       "      <td>52-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-312.0</td>\n",
       "      <td>-311.0</td>\n",
       "      <td>-307.0</td>\n",
       "      <td>-313.0</td>\n",
       "      <td>-317.0</td>\n",
       "      <td>-317.0</td>\n",
       "      <td>-320.0</td>\n",
       "      <td>-321.0</td>\n",
       "      <td>-330.0</td>\n",
       "      <td>-331.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.462072</td>\n",
       "      <td>1.527700e+09</td>\n",
       "      <td>52-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-408.0</td>\n",
       "      <td>-420.0</td>\n",
       "      <td>-413.0</td>\n",
       "      <td>-408.0</td>\n",
       "      <td>-410.0</td>\n",
       "      <td>-425.0</td>\n",
       "      <td>-425.0</td>\n",
       "      <td>-413.0</td>\n",
       "      <td>-374.0</td>\n",
       "      <td>-343.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.516548</td>\n",
       "      <td>1.527700e+09</td>\n",
       "      <td>52-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-343.0</td>\n",
       "      <td>-331.0</td>\n",
       "      <td>-324.0</td>\n",
       "      <td>-312.0</td>\n",
       "      <td>-306.0</td>\n",
       "      <td>-301.0</td>\n",
       "      <td>-302.0</td>\n",
       "      <td>-306.0</td>\n",
       "      <td>-312.0</td>\n",
       "      <td>-312.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.591766</td>\n",
       "      <td>1.527700e+09</td>\n",
       "      <td>52-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9  ...  \\\n",
       "0 -426.0 -413.0 -394.0 -367.0 -340.0 -313.0 -286.0 -261.0 -235.0 -220.0  ...   \n",
       "1 -362.0 -362.0 -362.0 -352.0 -343.0 -326.0 -324.0 -310.0 -299.0 -292.0  ...   \n",
       "2 -312.0 -311.0 -307.0 -313.0 -317.0 -317.0 -320.0 -321.0 -330.0 -331.0  ...   \n",
       "3 -408.0 -420.0 -413.0 -408.0 -410.0 -425.0 -425.0 -413.0 -374.0 -343.0  ...   \n",
       "4 -343.0 -331.0 -324.0 -312.0 -306.0 -301.0 -302.0 -306.0 -312.0 -312.0  ...   \n",
       "\n",
       "     293    294    295    296    297    298    299       300           301  \\\n",
       "0  115.0  115.0  107.0  103.0   96.0   98.0   98.0  0.133031  1.527700e+09   \n",
       "1   77.0   75.0   71.0   64.0   53.0   45.0   43.0  0.328511  1.527700e+09   \n",
       "2   25.0   22.0   14.0   13.0   28.0   67.0  100.0  0.462072  1.527700e+09   \n",
       "3  108.0  107.0  108.0  114.0  115.0  108.0  103.0  0.516548  1.527700e+09   \n",
       "4   55.0   51.0   45.0   44.0   38.0   36.0   34.0  0.591766  1.527700e+09   \n",
       "\n",
       "    302  \n",
       "0  52-1  \n",
       "1  52-1  \n",
       "2  52-1  \n",
       "3  52-1  \n",
       "4  52-1  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset=pd.read_csv(\"../data/processed/mlp_dataset_raw_xyz.csv\",index_col=False )\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.iloc[:,0:300].values\n",
    "y=dataset.iloc[:,300].values\n",
    "\n",
    "#Split training/testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "run1 = {\n",
    "    'name': 'param1',\n",
    "    'scaler': StandardScaler(),  # standard, minmax, maxabs \n",
    "    'batch_size': 16,\n",
    "    'epochs':80,\n",
    "    'nodes': [128],  \n",
    "    'act': ['relu'],\n",
    "    'dropout': [0],  # dropout 0 means keep all nodes\n",
    "    'loss': 'mean_squared_error',\n",
    "    'metrics': ['mean_squared_error']\n",
    "}\n",
    "\n",
    "\n",
    "run2 = {\n",
    "    'name': 'param2',\n",
    "    'scaler': StandardScaler(),  # standard, minmax, maxabs \n",
    "    'batch_size': 32,\n",
    "    'epochs': 10,\n",
    "    'nodes': [128],  \n",
    "    'act': ['relu'],\n",
    "    'dropout': [0],  # dropout 0 means keep all nodes\n",
    "    'loss': 'mean_squared_error',\n",
    "    'metrics': ['mean_squared_error']\n",
    "}\n",
    "\n",
    "run3 = {\n",
    "    'name': 'param3',\n",
    "    'scaler': StandardScaler(),  # standard, minmax, maxabs \n",
    "    'batch_size': 32,\n",
    "    'epochs': 20,\n",
    "    'nodes': [128],  \n",
    "    'act': ['relu'],\n",
    "    'dropout': [0],  # dropout 0 means keep all nodes\n",
    "    'loss': 'mean_squared_error',\n",
    "    'metrics': ['mean_squared_error']\n",
    "}\n",
    "\n",
    "run4 = {\n",
    "    'name': 'param4',\n",
    "    'scaler': StandardScaler(),  # standard, minmax, maxabs\n",
    "    'batch_size': 16,\n",
    "    'epochs': 80,\n",
    "    'nodes': [256, 128],  \n",
    "    'act': ['relu', 'relu'],\n",
    "    'dropout': [0.8, 0.8],  # dropout 0 means keep all nodes\n",
    "    'loss': 'mean_squared_error',\n",
    "    'metrics': ['mean_squared_error']\n",
    "}\n",
    "\n",
    "\n",
    "grid=[run1, run4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(inp_dim, run): #Functional API #Default initializer for all layers is Xavier (aka glorot_uniform)\n",
    "    inputs = keras.Input(shape=(inp_dim,), name='input') \n",
    "    x = Dense(run['nodes'][0], activation=run['act'][0])(inputs)\n",
    "    x = Dropout(run['dropout'][0])(x)\n",
    "    for i in range(int(len(run['nodes'])-1)):\n",
    "        x = Dense(run['nodes'][i+1], activation=run['act'][i+1])(x)\n",
    "        x=Dropout(run['dropout'][i+1])(x)\n",
    "    outputs = Dense(1, activation='linear')(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-06 10:00:01.202449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-01-06 10:00:01.318328: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-01-06 10:00:01.318351: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-01-06 10:00:01.319140: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.2109 - mean_squared_error: 0.2109 - val_loss: 0.1219 - val_mean_squared_error: 0.1219\n",
      "Epoch 2/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0929 - mean_squared_error: 0.0929 - val_loss: 0.0833 - val_mean_squared_error: 0.0833\n",
      "Epoch 3/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0797 - mean_squared_error: 0.0797 - val_loss: 0.0750 - val_mean_squared_error: 0.0750\n",
      "Epoch 4/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0671 - mean_squared_error: 0.0671 - val_loss: 0.0702 - val_mean_squared_error: 0.0702\n",
      "Epoch 5/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0602 - mean_squared_error: 0.0602 - val_loss: 0.0625 - val_mean_squared_error: 0.0625\n",
      "Epoch 6/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0588 - mean_squared_error: 0.0588 - val_loss: 0.0600 - val_mean_squared_error: 0.0600\n",
      "Epoch 7/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0582 - mean_squared_error: 0.0582 - val_loss: 0.0600 - val_mean_squared_error: 0.0600\n",
      "Epoch 8/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0583 - mean_squared_error: 0.0583 - val_loss: 0.0594 - val_mean_squared_error: 0.0594\n",
      "Epoch 9/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0579 - mean_squared_error: 0.0579 - val_loss: 0.0613 - val_mean_squared_error: 0.0613\n",
      "Epoch 10/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0574 - mean_squared_error: 0.0574 - val_loss: 0.0631 - val_mean_squared_error: 0.0631\n",
      "Epoch 11/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0566 - mean_squared_error: 0.0566 - val_loss: 0.0639 - val_mean_squared_error: 0.0639\n",
      "Epoch 12/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0565 - mean_squared_error: 0.0565 - val_loss: 0.0597 - val_mean_squared_error: 0.0597\n",
      "Epoch 13/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0566 - mean_squared_error: 0.0566 - val_loss: 0.0582 - val_mean_squared_error: 0.0582\n",
      "Epoch 14/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0564 - mean_squared_error: 0.0564 - val_loss: 0.0639 - val_mean_squared_error: 0.0639\n",
      "Epoch 15/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0557 - mean_squared_error: 0.0557 - val_loss: 0.0641 - val_mean_squared_error: 0.0641\n",
      "Epoch 16/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0551 - mean_squared_error: 0.0551 - val_loss: 0.0613 - val_mean_squared_error: 0.0613\n",
      "Epoch 17/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0548 - mean_squared_error: 0.0548 - val_loss: 0.0604 - val_mean_squared_error: 0.0604\n",
      "Epoch 18/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0546 - mean_squared_error: 0.0546 - val_loss: 0.0613 - val_mean_squared_error: 0.0613\n",
      "Epoch 19/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0545 - mean_squared_error: 0.0545 - val_loss: 0.0642 - val_mean_squared_error: 0.0642\n",
      "Epoch 20/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0539 - mean_squared_error: 0.0539 - val_loss: 0.0616 - val_mean_squared_error: 0.0616\n",
      "Epoch 21/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0535 - mean_squared_error: 0.0535 - val_loss: 0.0649 - val_mean_squared_error: 0.0649\n",
      "Epoch 22/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0530 - mean_squared_error: 0.0530 - val_loss: 0.0624 - val_mean_squared_error: 0.0624\n",
      "Epoch 23/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0528 - mean_squared_error: 0.0528 - val_loss: 0.0645 - val_mean_squared_error: 0.0645\n",
      "Epoch 24/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0528 - mean_squared_error: 0.0528 - val_loss: 0.0637 - val_mean_squared_error: 0.0637\n",
      "Epoch 25/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0523 - mean_squared_error: 0.0523 - val_loss: 0.0673 - val_mean_squared_error: 0.0673\n",
      "Epoch 26/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0518 - mean_squared_error: 0.0518 - val_loss: 0.0634 - val_mean_squared_error: 0.0634\n",
      "Epoch 27/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0516 - mean_squared_error: 0.0516 - val_loss: 0.0669 - val_mean_squared_error: 0.0669\n",
      "Epoch 28/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0514 - mean_squared_error: 0.0514 - val_loss: 0.0664 - val_mean_squared_error: 0.0664\n",
      "Epoch 29/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0511 - mean_squared_error: 0.0511 - val_loss: 0.0668 - val_mean_squared_error: 0.0668\n",
      "Epoch 30/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0509 - mean_squared_error: 0.0509 - val_loss: 0.0636 - val_mean_squared_error: 0.0636\n",
      "Epoch 31/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0506 - mean_squared_error: 0.0506 - val_loss: 0.0714 - val_mean_squared_error: 0.0714\n",
      "Epoch 32/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0501 - mean_squared_error: 0.0501 - val_loss: 0.0672 - val_mean_squared_error: 0.0672\n",
      "Epoch 33/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0502 - mean_squared_error: 0.0502 - val_loss: 0.0707 - val_mean_squared_error: 0.0707\n",
      "Epoch 34/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0499 - mean_squared_error: 0.0499 - val_loss: 0.0660 - val_mean_squared_error: 0.0660\n",
      "Epoch 35/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0497 - mean_squared_error: 0.0497 - val_loss: 0.0656 - val_mean_squared_error: 0.0656\n",
      "Epoch 36/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0496 - mean_squared_error: 0.0496 - val_loss: 0.0665 - val_mean_squared_error: 0.0665\n",
      "Epoch 37/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0487 - mean_squared_error: 0.0487 - val_loss: 0.0738 - val_mean_squared_error: 0.0738\n",
      "Epoch 38/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0498 - mean_squared_error: 0.0498 - val_loss: 0.0678 - val_mean_squared_error: 0.0678\n",
      "Epoch 39/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0487 - mean_squared_error: 0.0487 - val_loss: 0.0673 - val_mean_squared_error: 0.0673\n",
      "Epoch 40/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0485 - mean_squared_error: 0.0485 - val_loss: 0.0671 - val_mean_squared_error: 0.0671\n",
      "Epoch 41/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0481 - mean_squared_error: 0.0481 - val_loss: 0.0658 - val_mean_squared_error: 0.0658\n",
      "Epoch 42/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0483 - mean_squared_error: 0.0483 - val_loss: 0.0681 - val_mean_squared_error: 0.0681\n",
      "Epoch 43/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0480 - mean_squared_error: 0.0480 - val_loss: 0.0703 - val_mean_squared_error: 0.0703\n",
      "Epoch 44/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0477 - mean_squared_error: 0.0477 - val_loss: 0.0666 - val_mean_squared_error: 0.0666\n",
      "Epoch 45/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0480 - mean_squared_error: 0.0480 - val_loss: 0.0692 - val_mean_squared_error: 0.0692\n",
      "Epoch 46/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0472 - mean_squared_error: 0.0472 - val_loss: 0.0692 - val_mean_squared_error: 0.0692\n",
      "Epoch 47/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0477 - mean_squared_error: 0.0477 - val_loss: 0.0674 - val_mean_squared_error: 0.0674\n",
      "Epoch 48/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0468 - mean_squared_error: 0.0468 - val_loss: 0.0677 - val_mean_squared_error: 0.0677\n",
      "Epoch 49/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0465 - mean_squared_error: 0.0465 - val_loss: 0.0711 - val_mean_squared_error: 0.0711\n",
      "Epoch 50/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0472 - mean_squared_error: 0.0472 - val_loss: 0.0736 - val_mean_squared_error: 0.0736\n",
      "Epoch 51/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0467 - mean_squared_error: 0.0467 - val_loss: 0.0678 - val_mean_squared_error: 0.0678\n",
      "Epoch 52/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0468 - mean_squared_error: 0.0468 - val_loss: 0.0712 - val_mean_squared_error: 0.0712\n",
      "Epoch 53/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0474 - mean_squared_error: 0.0474 - val_loss: 0.0696 - val_mean_squared_error: 0.0696\n",
      "Epoch 54/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0454 - mean_squared_error: 0.0454 - val_loss: 0.0708 - val_mean_squared_error: 0.0708\n",
      "Epoch 55/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0453 - mean_squared_error: 0.0453 - val_loss: 0.0719 - val_mean_squared_error: 0.0719\n",
      "Epoch 56/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0455 - mean_squared_error: 0.0455 - val_loss: 0.0695 - val_mean_squared_error: 0.0695\n",
      "Epoch 57/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0451 - mean_squared_error: 0.0451 - val_loss: 0.0695 - val_mean_squared_error: 0.0695\n",
      "Epoch 58/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0450 - mean_squared_error: 0.0450 - val_loss: 0.0720 - val_mean_squared_error: 0.0720\n",
      "Epoch 59/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0451 - mean_squared_error: 0.0451 - val_loss: 0.0692 - val_mean_squared_error: 0.0692\n",
      "Epoch 60/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0454 - mean_squared_error: 0.0454 - val_loss: 0.0686 - val_mean_squared_error: 0.0686\n",
      "Epoch 61/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0444 - mean_squared_error: 0.0444 - val_loss: 0.0706 - val_mean_squared_error: 0.0706\n",
      "Epoch 62/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0440 - mean_squared_error: 0.0440 - val_loss: 0.0684 - val_mean_squared_error: 0.0684\n",
      "Epoch 63/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0452 - mean_squared_error: 0.0452 - val_loss: 0.0707 - val_mean_squared_error: 0.0707\n",
      "Epoch 64/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0449 - mean_squared_error: 0.0449 - val_loss: 0.0665 - val_mean_squared_error: 0.0665\n",
      "Epoch 65/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0435 - mean_squared_error: 0.0435 - val_loss: 0.0720 - val_mean_squared_error: 0.0720\n",
      "Epoch 66/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0440 - mean_squared_error: 0.0440 - val_loss: 0.0685 - val_mean_squared_error: 0.0685\n",
      "Epoch 67/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0445 - mean_squared_error: 0.0445 - val_loss: 0.0725 - val_mean_squared_error: 0.0725\n",
      "Epoch 68/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0445 - mean_squared_error: 0.0445 - val_loss: 0.0657 - val_mean_squared_error: 0.0657\n",
      "Epoch 69/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0442 - mean_squared_error: 0.0442 - val_loss: 0.0703 - val_mean_squared_error: 0.0703\n",
      "Epoch 70/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0434 - mean_squared_error: 0.0434 - val_loss: 0.0692 - val_mean_squared_error: 0.0692\n",
      "Epoch 71/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0437 - mean_squared_error: 0.0437 - val_loss: 0.0726 - val_mean_squared_error: 0.0726\n",
      "Epoch 72/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0437 - mean_squared_error: 0.0437 - val_loss: 0.0703 - val_mean_squared_error: 0.0703\n",
      "Epoch 73/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0431 - mean_squared_error: 0.0431 - val_loss: 0.0724 - val_mean_squared_error: 0.0724\n",
      "Epoch 74/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0425 - mean_squared_error: 0.0425 - val_loss: 0.0708 - val_mean_squared_error: 0.0708\n",
      "Epoch 75/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0427 - mean_squared_error: 0.0427 - val_loss: 0.0695 - val_mean_squared_error: 0.0695\n",
      "Epoch 76/80\n",
      "919/919 [==============================] - 1s 2ms/step - loss: 0.0425 - mean_squared_error: 0.0425 - val_loss: 0.0702 - val_mean_squared_error: 0.0702\n",
      "Epoch 77/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0432 - mean_squared_error: 0.0432 - val_loss: 0.0703 - val_mean_squared_error: 0.0703\n",
      "Epoch 78/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0428 - mean_squared_error: 0.0428 - val_loss: 0.0754 - val_mean_squared_error: 0.0754\n",
      "Epoch 79/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0426 - mean_squared_error: 0.0426 - val_loss: 0.0713 - val_mean_squared_error: 0.0713\n",
      "Epoch 80/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0426 - mean_squared_error: 0.0426 - val_loss: 0.0745 - val_mean_squared_error: 0.0745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-06 10:02:08.456575: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpzd52vkke/model/data/model/assets\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0712 - mean_squared_error: 0.0712\n",
      "Epoch 1/80\n",
      "  1/919 [..............................] - ETA: 4:51 - loss: 7.8156 - mean_squared_error: 7.8156WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0023s). Check your callbacks.\n",
      "919/919 [==============================] - 3s 3ms/step - loss: 2.8752 - mean_squared_error: 2.8752 - val_loss: 0.1475 - val_mean_squared_error: 0.1475\n",
      "Epoch 2/80\n",
      "919/919 [==============================] - 3s 4ms/step - loss: 0.2249 - mean_squared_error: 0.2249 - val_loss: 0.1046 - val_mean_squared_error: 0.1046\n",
      "Epoch 3/80\n",
      "919/919 [==============================] - 3s 3ms/step - loss: 0.1440 - mean_squared_error: 0.1440 - val_loss: 0.0948 - val_mean_squared_error: 0.0948\n",
      "Epoch 4/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.1133 - mean_squared_error: 0.1133 - val_loss: 0.0936 - val_mean_squared_error: 0.0936\n",
      "Epoch 5/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.1073 - mean_squared_error: 0.1073 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
      "Epoch 6/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0961 - mean_squared_error: 0.0961 - val_loss: 0.0937 - val_mean_squared_error: 0.0937\n",
      "Epoch 7/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0948 - mean_squared_error: 0.0948 - val_loss: 0.0921 - val_mean_squared_error: 0.0921\n",
      "Epoch 8/80\n",
      "919/919 [==============================] - 3s 3ms/step - loss: 0.0895 - mean_squared_error: 0.0895 - val_loss: 0.0904 - val_mean_squared_error: 0.0904\n",
      "Epoch 9/80\n",
      "919/919 [==============================] - 4s 4ms/step - loss: 0.0881 - mean_squared_error: 0.0881 - val_loss: 0.0904 - val_mean_squared_error: 0.0904\n",
      "Epoch 10/80\n",
      "919/919 [==============================] - 4s 4ms/step - loss: 0.0864 - mean_squared_error: 0.0864 - val_loss: 0.0883 - val_mean_squared_error: 0.0883\n",
      "Epoch 11/80\n",
      "919/919 [==============================] - 3s 3ms/step - loss: 0.0922 - mean_squared_error: 0.0922 - val_loss: 0.0930 - val_mean_squared_error: 0.0930\n",
      "Epoch 12/80\n",
      "919/919 [==============================] - 3s 3ms/step - loss: 0.0889 - mean_squared_error: 0.0889 - val_loss: 0.0900 - val_mean_squared_error: 0.0900\n",
      "Epoch 13/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0916 - mean_squared_error: 0.0916 - val_loss: 0.0913 - val_mean_squared_error: 0.0913\n",
      "Epoch 14/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0887 - mean_squared_error: 0.0887 - val_loss: 0.0960 - val_mean_squared_error: 0.0960\n",
      "Epoch 15/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0902 - mean_squared_error: 0.0902 - val_loss: 0.0914 - val_mean_squared_error: 0.0914\n",
      "Epoch 16/80\n",
      "919/919 [==============================] - 3s 3ms/step - loss: 0.0868 - mean_squared_error: 0.0868 - val_loss: 0.0901 - val_mean_squared_error: 0.0901\n",
      "Epoch 17/80\n",
      "919/919 [==============================] - 3s 3ms/step - loss: 0.0897 - mean_squared_error: 0.0897 - val_loss: 0.0833 - val_mean_squared_error: 0.0833\n",
      "Epoch 18/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0832 - mean_squared_error: 0.0832 - val_loss: 0.0813 - val_mean_squared_error: 0.0813\n",
      "Epoch 19/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0853 - mean_squared_error: 0.0853 - val_loss: 0.0815 - val_mean_squared_error: 0.0815\n",
      "Epoch 20/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0854 - mean_squared_error: 0.0854 - val_loss: 0.0836 - val_mean_squared_error: 0.0836\n",
      "Epoch 21/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0846 - mean_squared_error: 0.0846 - val_loss: 0.0823 - val_mean_squared_error: 0.0823\n",
      "Epoch 22/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0858 - mean_squared_error: 0.0858 - val_loss: 0.0815 - val_mean_squared_error: 0.0815\n",
      "Epoch 23/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0835 - mean_squared_error: 0.0835 - val_loss: 0.0813 - val_mean_squared_error: 0.0813\n",
      "Epoch 24/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0816 - mean_squared_error: 0.0816 - val_loss: 0.0812 - val_mean_squared_error: 0.0812\n",
      "Epoch 25/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0844 - mean_squared_error: 0.0844 - val_loss: 0.0796 - val_mean_squared_error: 0.0796\n",
      "Epoch 26/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0862 - mean_squared_error: 0.0862 - val_loss: 0.0838 - val_mean_squared_error: 0.0838\n",
      "Epoch 27/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0871 - mean_squared_error: 0.0871 - val_loss: 0.0809 - val_mean_squared_error: 0.0809\n",
      "Epoch 28/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0863 - mean_squared_error: 0.0863 - val_loss: 0.0804 - val_mean_squared_error: 0.0804\n",
      "Epoch 29/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0875 - mean_squared_error: 0.0875 - val_loss: 0.0806 - val_mean_squared_error: 0.0806\n",
      "Epoch 30/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0837 - mean_squared_error: 0.0837 - val_loss: 0.0800 - val_mean_squared_error: 0.0800\n",
      "Epoch 31/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0811 - mean_squared_error: 0.0811 - val_loss: 0.0808 - val_mean_squared_error: 0.0808\n",
      "Epoch 32/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0838 - mean_squared_error: 0.0838 - val_loss: 0.0783 - val_mean_squared_error: 0.0783\n",
      "Epoch 33/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0813 - mean_squared_error: 0.0813 - val_loss: 0.0775 - val_mean_squared_error: 0.0775\n",
      "Epoch 34/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0819 - mean_squared_error: 0.0819 - val_loss: 0.0792 - val_mean_squared_error: 0.0792\n",
      "Epoch 35/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_squared_error: 0.0821 - val_loss: 0.0811 - val_mean_squared_error: 0.0811\n",
      "Epoch 36/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_squared_error: 0.0830 - val_loss: 0.0801 - val_mean_squared_error: 0.0801\n",
      "Epoch 37/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0807 - mean_squared_error: 0.0807 - val_loss: 0.0798 - val_mean_squared_error: 0.0798\n",
      "Epoch 38/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0847 - mean_squared_error: 0.0847 - val_loss: 0.0804 - val_mean_squared_error: 0.0804\n",
      "Epoch 39/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0800 - mean_squared_error: 0.0800 - val_loss: 0.0782 - val_mean_squared_error: 0.0782\n",
      "Epoch 40/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0850 - mean_squared_error: 0.0850 - val_loss: 0.0775 - val_mean_squared_error: 0.0775\n",
      "Epoch 41/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0803 - mean_squared_error: 0.0803 - val_loss: 0.0779 - val_mean_squared_error: 0.0779\n",
      "Epoch 42/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0827 - mean_squared_error: 0.0827 - val_loss: 0.0783 - val_mean_squared_error: 0.0783\n",
      "Epoch 43/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0884 - mean_squared_error: 0.0884 - val_loss: 0.0787 - val_mean_squared_error: 0.0787\n",
      "Epoch 44/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0848 - mean_squared_error: 0.0848 - val_loss: 0.0784 - val_mean_squared_error: 0.0784\n",
      "Epoch 45/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0850 - mean_squared_error: 0.0850 - val_loss: 0.0779 - val_mean_squared_error: 0.0779\n",
      "Epoch 46/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0827 - mean_squared_error: 0.0827 - val_loss: 0.0780 - val_mean_squared_error: 0.0780\n",
      "Epoch 47/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0819 - mean_squared_error: 0.0819 - val_loss: 0.0799 - val_mean_squared_error: 0.0799\n",
      "Epoch 48/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0818 - mean_squared_error: 0.0818 - val_loss: 0.0778 - val_mean_squared_error: 0.0778\n",
      "Epoch 49/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0840 - mean_squared_error: 0.0840 - val_loss: 0.0789 - val_mean_squared_error: 0.0789\n",
      "Epoch 50/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_squared_error: 0.0821 - val_loss: 0.0795 - val_mean_squared_error: 0.0795\n",
      "Epoch 51/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0817 - mean_squared_error: 0.0817 - val_loss: 0.0776 - val_mean_squared_error: 0.0776\n",
      "Epoch 52/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0861 - mean_squared_error: 0.0861 - val_loss: 0.0776 - val_mean_squared_error: 0.0776\n",
      "Epoch 53/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0832 - mean_squared_error: 0.0832 - val_loss: 0.0773 - val_mean_squared_error: 0.0773\n",
      "Epoch 54/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0799 - mean_squared_error: 0.0799 - val_loss: 0.0771 - val_mean_squared_error: 0.0771\n",
      "Epoch 55/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0852 - mean_squared_error: 0.0852 - val_loss: 0.0778 - val_mean_squared_error: 0.0778\n",
      "Epoch 56/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0836 - mean_squared_error: 0.0836 - val_loss: 0.0782 - val_mean_squared_error: 0.0782\n",
      "Epoch 57/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0830 - mean_squared_error: 0.0830 - val_loss: 0.0772 - val_mean_squared_error: 0.0772\n",
      "Epoch 58/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0828 - mean_squared_error: 0.0828 - val_loss: 0.0805 - val_mean_squared_error: 0.0805\n",
      "Epoch 59/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0841 - mean_squared_error: 0.0841 - val_loss: 0.0786 - val_mean_squared_error: 0.0786\n",
      "Epoch 60/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0813 - mean_squared_error: 0.0813 - val_loss: 0.0779 - val_mean_squared_error: 0.0779\n",
      "Epoch 61/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0821 - mean_squared_error: 0.0821 - val_loss: 0.0791 - val_mean_squared_error: 0.0791\n",
      "Epoch 62/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0845 - mean_squared_error: 0.0845 - val_loss: 0.0788 - val_mean_squared_error: 0.0788\n",
      "Epoch 63/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0816 - mean_squared_error: 0.0816 - val_loss: 0.0775 - val_mean_squared_error: 0.0775\n",
      "Epoch 64/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0841 - mean_squared_error: 0.0841 - val_loss: 0.0781 - val_mean_squared_error: 0.0781\n",
      "Epoch 65/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0816 - mean_squared_error: 0.0816 - val_loss: 0.0776 - val_mean_squared_error: 0.0776\n",
      "Epoch 66/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0842 - mean_squared_error: 0.0842 - val_loss: 0.0798 - val_mean_squared_error: 0.0798\n",
      "Epoch 67/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0855 - mean_squared_error: 0.0855 - val_loss: 0.0793 - val_mean_squared_error: 0.0793\n",
      "Epoch 68/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0832 - mean_squared_error: 0.0832 - val_loss: 0.0784 - val_mean_squared_error: 0.0784\n",
      "Epoch 69/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0811 - mean_squared_error: 0.0811 - val_loss: 0.0782 - val_mean_squared_error: 0.0782\n",
      "Epoch 70/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0815 - mean_squared_error: 0.0815 - val_loss: 0.0794 - val_mean_squared_error: 0.0794\n",
      "Epoch 71/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0824 - mean_squared_error: 0.0824 - val_loss: 0.0778 - val_mean_squared_error: 0.0778\n",
      "Epoch 72/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0832 - mean_squared_error: 0.0832 - val_loss: 0.0778 - val_mean_squared_error: 0.0778\n",
      "Epoch 73/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0859 - mean_squared_error: 0.0859 - val_loss: 0.0789 - val_mean_squared_error: 0.0789\n",
      "Epoch 74/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0818 - mean_squared_error: 0.0818 - val_loss: 0.0774 - val_mean_squared_error: 0.0774\n",
      "Epoch 75/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0823 - mean_squared_error: 0.0823 - val_loss: 0.0784 - val_mean_squared_error: 0.0784\n",
      "Epoch 76/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0864 - mean_squared_error: 0.0864 - val_loss: 0.0782 - val_mean_squared_error: 0.0782\n",
      "Epoch 77/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0840 - mean_squared_error: 0.0840 - val_loss: 0.0789 - val_mean_squared_error: 0.0789\n",
      "Epoch 78/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0851 - mean_squared_error: 0.0851 - val_loss: 0.0792 - val_mean_squared_error: 0.0792\n",
      "Epoch 79/80\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.0842 - mean_squared_error: 0.0842 - val_loss: 0.0787 - val_mean_squared_error: 0.0787\n",
      "Epoch 80/80\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.0811 - mean_squared_error: 0.0811 - val_loss: 0.0778 - val_mean_squared_error: 0.0778\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp05h94bo_/model/data/model/assets\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0774 - mean_squared_error: 0.0774\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Gait Speed Prediction\")\n",
    "\n",
    "for i,run in enumerate(grid):\n",
    "    scaler=run['scaler']\n",
    "    sX_train=scaler.fit_transform(X_train)\n",
    "    pickle.dump(scaler, open('scaler.pkl', 'wb'))\n",
    "    mlflow.start_run(run_name='raw_unrounded-'+str(i))\n",
    "    mlflow.log_artifact('scaler.pkl')\n",
    "    model=define_model(X.shape[1], run)\n",
    "    model.compile(loss=run['loss'] , optimizer=\"adam\", metrics=run['metrics'])\n",
    "    mlflow.tensorflow.autolog(every_n_iter=2)\n",
    "    history = model.fit(sX_train,y_train, batch_size=run['batch_size'], epochs=run['epochs'], verbose=1, validation_split=0.1)\n",
    "    # Testing\n",
    "    sX_test=scaler.transform(X_test)\n",
    "    score = model.evaluate(sX_test, y_test,  verbose=1)\n",
    "    mlflow.log_metrics({'test_loss': score[0], 'test_rmse': np.sqrt(score[1])})\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samer/miniconda3/envs/gait_speed_prediction/lib/python3.9/site-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.46681085],\n",
       "       [0.38615432],\n",
       "       [0.46681085],\n",
       "       ...,\n",
       "       [0.46681085],\n",
       "       [0.4615082 ],\n",
       "       [0.46681085]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting based on selected run\n",
    "\n",
    "#Retrieve Scaler\n",
    "client = mlflow.tracking.MlflowClient() \n",
    "local_dir = \"/tmp/artifact_downloads\" \n",
    "if not os.path.exists(local_dir): \n",
    "\tos.mkdir(local_dir) \n",
    "\n",
    "local_path = client.download_artifacts('3329b6cce2fd426cad7194f9da526103', '', local_dir) \n",
    "file = open('/tmp/artifact_downloads/scaler.pkl', 'rb')\n",
    "scaler=pickle.load(file)\n",
    "\n",
    "#Retrieve Model\n",
    "logged_model = 'runs:/3329b6cce2fd426cad7194f9da526103/model'\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "#Predict \n",
    "sX_test=scaler.transform(X_test)\n",
    "loaded_model.predict(sX_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93e0bbc3472066dbd55e296a1d0e4e362e1f6aff5ea5fd2a3cea8bcfd0db6851"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
