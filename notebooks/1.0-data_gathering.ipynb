{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cfceac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "import datetime\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b80da573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#derived data\n",
    "annotation=pd.read_csv(\"../data/derived_data/annotation.csv\")\n",
    "raw_meta=pd.read_csv(\"../data/derived_data/raw-meta.csv\")\n",
    "section_speed=pd.read_csv(\"../data/derived_data/section-speed.csv\")\n",
    "steps=pd.read_csv(\"../data/derived_data/steps.csv\")\n",
    "wheel=pd.read_csv(\"../data/derived_data/wheel.csv\")\n",
    "\n",
    "#raw data\n",
    "sync=pd.read_csv(\"../data/raw_data/sync.csv\")\n",
    "raw_file=\"../data/raw_data/raw.h5\"\n",
    "raw=h5py.File(raw_file,\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84f674e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cols_to_time(dataframe, columns_to_convert):\n",
    "    \"\"\" A function that converts columns specified by 'columns_to_convert' in the 'dataframe' into epoch time and returns the converted dataframe\"\"\"\n",
    "    for col in columns_to_convert:\n",
    "        dataframe[col]=dataframe[col].apply(lambda x: pd.Timestamp(x).timestamp())\n",
    "    return dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7ec994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sync=convert_cols_to_time(sync,['subject.start','subject.end','wheel.start','wheel.end','video.start'])\n",
    "wheel=convert_cols_to_time(wheel,['start','end'])\n",
    "wheel['mid']=wheel['start']+0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "059ee70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct expanded sync dataframe with omitted unnecessary fields\n",
    "data_columns=[\"stamp\",\"SubjectId\",\"RunId\",\"x\",\"y\",\"z\",\"speed\"]\n",
    "data=[]\n",
    "for idx, row in sync.iterrows():\n",
    "\n",
    "    \n",
    "    subject_id=row['SubjectId']\n",
    "    run_id=row['RunId']\n",
    "    subject_start=row['subject.start']\n",
    "    delta=row['subject.delta']/100\n",
    "\n",
    "\n",
    "    # Fetch subject raw accelerometer data from raw.h5 \n",
    "    path_to_subject=row[\"subject.path\"]\n",
    "    subject_data=raw.get(path_to_subject)\n",
    "    subject_data=list(subject_data)\n",
    "    subject_data=np.array(subject_data).T\n",
    "\n",
    "\n",
    "    # Generate corrected stamps corresponding to subject sensor entries\n",
    "    # old_stamps=np.linspace(subject_start-delta,subject_start-delta+len(subject_data)/100, len(subject_data))\n",
    "\n",
    "    stamps=0.01*np.arange(len(subject_data))+subject_start-delta\n",
    "    speeds=np.zeros_like(stamps)\n",
    "    subjects=subject_id*np.ones_like(stamps)\n",
    "    runs=run_id*np.ones_like(stamps)\n",
    "\n",
    "\n",
    "    # lookup average speed data from wheel.csv based on SubjectId, RunId, and nearest number of wheel start time to corrected subject start time \n",
    "    run_wheel_data=wheel.loc[(wheel['SubjectId']==subject_id ) & (wheel['RunId']==run_id)]\n",
    "    first_speed_stamp=run_wheel_data[\"start\"].iloc[0]\n",
    "    last_speed_stamp=run_wheel_data[\"end\"].iloc[-1]\n",
    "    for i in range(len(stamps)):   \n",
    "        time_idx=np.argmin(np.abs(run_wheel_data['mid'].values-stamps[i]))\n",
    "        speeds[i]=run_wheel_data['speed'].values[time_idx]\n",
    "\n",
    "    # Construct table for this subject run\n",
    "    run_gathered_data=np.concatenate([stamps.reshape(-1,1),subjects.reshape(-1,1),runs.reshape(-1,1),subject_data[:,0:-1], speeds.reshape(-1,1)], axis=1) #added stamps and dropped last KSS column\n",
    "    \n",
    "    # discard all samples that started before initial_speed_stamp and continued after last_speed_stamp\n",
    "    run_gathered_data=run_gathered_data[run_gathered_data[:,0]>first_speed_stamp]\n",
    "    run_gathered_data=run_gathered_data[run_gathered_data[:,0]<last_speed_stamp]\n",
    "    # discard samples with inf speed (This will generate discontinuities in the collection of  time series)\n",
    "    run_gathered_data=run_gathered_data[run_gathered_data[:,-1]!=np.inf] \n",
    "\n",
    "    data.append(run_gathered_data)\n",
    "\n",
    "    # # Fetch wheel raw accelerometer data from raw.h5 (no correction needed since wheel is reference)\n",
    "    # path_to_wheel=row[\"wheel.path\"]\t\n",
    "    # wheel_data=raw.get(path_to_wheel)\n",
    "    # wheel_data=list(wheel_data)\n",
    "    # wheel_data=np.array(wheel_data).T\n",
    "\n",
    "\n",
    "isExist = os.path.exists(\"../data/processed\")\n",
    "if not isExist:\n",
    "  os.makedirs(\"../data/processed\")\n",
    "\n",
    "data=np.concatenate(data)\n",
    "data=pd.DataFrame(data, columns=data_columns)\n",
    "data.to_csv(\"../data/processed/gathered.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b2c51d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
